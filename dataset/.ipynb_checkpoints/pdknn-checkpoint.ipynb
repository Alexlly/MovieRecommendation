{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql.functions import mean, col\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "import numpy as np\n",
    "os.environ['JAVA_HOME'] = '/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home'\n",
    "\n",
    "sc = SparkContext('local')\n",
    "spark = SparkSession(sc).builder.config(\"spark.sql.pivotMaxValues\", 2000000).getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"loading the datasets\"\"\"\n",
    "ratings = spark.read.load('./ml-20m/ratings.csv', format='csv', header=True, inferSchema=True).drop(\"timestamp\")\n",
    "movies = spark.read.load('./ml-20m/movies.csv', format='csv', header=True, inferSchema=True)\n",
    "\n",
    "\"\"\"calculating the average rating and number of ratings of each movie\"\"\"\n",
    "df = ratings.join(movies, on=\"movieId\")\n",
    "number_ratings = df.groupBy('movieId').count()\n",
    "average_ratings = df.groupBy('movieId').avg('rating')\n",
    "df_ratings = average_ratings.join(number_ratings, on=\"movieId\")\n",
    "df = df.join(df_ratings, on=\"movieId\")\n",
    "mostRatedMovies = df.where(\"count >= 50\")\n",
    "\n",
    "\"\"\"calculating the weighted average score of each movie\"\"\"\n",
    "# We have to convert the 'vote_count' column which is a string type to a double type (numerical) in order to calculate the quantile\n",
    "changedTypedf = mostRatedMovies.withColumn(\"vote_count\", df[\"count\"].cast(\"double\"))\n",
    "quantile_df = changedTypedf.approxQuantile(\"count\", [0.75], 0)\n",
    "m = quantile_df[0]\n",
    "\n",
    "# collect() is used to return all the elements of the dataset as an array at the driver program. This is usually useful after a filter\n",
    "# or other operation that returns a sufficiently small subset of the data.\n",
    "mean_df = mostRatedMovies.select(mean(col('avg(rating)')).alias('mean')).collect()\n",
    "C = mean_df[0]['mean']\n",
    "\n",
    "movies_cleaned_df = mostRatedMovies.withColumn(\"weighted_average\", ((mostRatedMovies['avg(rating)']*mostRatedMovies['count']) + (C*m)) / (mostRatedMovies['count']+m))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "\"\"\"creating a pivot table\"\"\"\n",
    "movies_pivot = mostRatedMovies.groupBy('title').pivot('userId').sum('rating').fillna(0)\n",
    "movie_features_df = movies_pivot.toPandas().set_index('title')\n",
    "movie_features_df_matrix = csr_matrix(movie_features_df.values)\n",
    "\n",
    "\"\"\"splitting the \"mostRatedMovies\" dataset into a train and test sets\"\"\"\n",
    "X = mostRatedMovies.toPandas()[['userId', 'movieId']].values\n",
    "y = mostRatedMovies.toPandas()['rating'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "\"\"\"fitting the data to the supervised kNeighborsRegressor model (to get predictions of the ratings)\"\"\"\n",
    "knn_reg = KNeighborsRegressor(n_neighbors=11, n_jobs=-1) # the first neighbor of a movie is the movie itself, so we specify 11\n",
    "knn_reg.fit(X_train, y_train)\n",
    "y_pred = knn_reg.predict(X_test)\n",
    "\n",
    "\"\"\"evaluating the kNeighborsRegressor model\"\"\"\n",
    "# out-of-sample evaluation\n",
    "rmse_test = sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Out-of-sample RMSE = \" + str(rmse_test))\n",
    "\n",
    "# in-sample-evaluation\n",
    "knn_reg_whole = KNeighborsRegressor(n_neighbors=11, n_jobs=-1)\n",
    "knn_reg_whole.fit(X, y)\n",
    "y_pred_whole = knn_reg_whole.predict(X)\n",
    "rmse = sqrt(mean_squared_error(y, y_pred_whole))\n",
    "print(\"Root-mean-square error = \" + str(rmse))\n",
    "\n",
    "\"\"\"fitting the final unsupervised model NearestNeighbors to find the most similar movies of each ones using the whole dataset\"\"\"\n",
    "model_knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=11, n_jobs=-1)\n",
    "model_knn.fit(movie_features_df_matrix)\n",
    "\n",
    "\"\"\"generating recommendations related to a movie chosed\"\"\"\n",
    "# choosing a title from our movie matrix\n",
    "favoriteMovie = 'Iron Man (2008)'\n",
    "query_index = movie_features_df.index.get_loc(favoriteMovie)\n",
    "distances, indices = model_knn.kneighbors(movie_features_df.loc[favoriteMovie,:].values.reshape(1, -1), n_neighbors=11)\n",
    "\n",
    "# printing the 10 most similar movies according to the kNN model\n",
    "for i in range(0, len(distances.flatten())):\n",
    "    if i == 0:\n",
    "        print('Recommendations for {0}:\\n'.format(movie_features_df.index[query_index]))\n",
    "    else:\n",
    "        print('{0}: {1}, with distance of {2}:'.format(i, movie_features_df.index[indices.flatten()[i]], distances.flatten()[i]))\n",
    "\n",
    "\"\"\"saving the files related to the model\"\"\"\n",
    "# saving the table to CSV file for later access\n",
    "movie_features_df.to_csv(os.path.join(trained_datapath, 'kNNmovieMatrix.csv'))\n",
    "\n",
    "# saving the model to disk\n",
    "file = open(os.path.join(trained_datapath, 'kNN_model.sav'), 'wb')\n",
    "pickle.dump(model_knn, file)\n",
    "\n",
    "# some time later... load the model from disk\n",
    "file_to_load = open(os.path.join(trained_datapath, 'kNN_model.sav'), 'rb')\n",
    "loaded_kNN_model = pickle.load(file_to_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
